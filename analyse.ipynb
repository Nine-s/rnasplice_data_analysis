{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        hostname  task_id       hash                            native_id  \\\n",
      "0  hu-worker-c27        5  90/a3cc1f  nf-90a3cc1f2cdfc19b35a9cdbdae48cc34   \n",
      "1  hu-worker-c24        3  f2/938a2e  nf-f2938a2e977b8b24b5ee4a3f64ef4059   \n",
      "2  hu-worker-c25        4  44/547e6d  nf-44547e6d76ad212a46f916b5cecc6361   \n",
      "3  hu-worker-c24        1  8c/886f80  nf-8c886f8078e73853475a073d52db85e6   \n",
      "4  hu-worker-c26        2  c3/1920aa  nf-c31920aa54f83f03f90353244aa2755d   \n",
      "\n",
      "                 process                                       tag  \\\n",
      "0        GFFREAD_TX2GENE  Drosophila_melanogaster.BDGP6.32.106.gtf   \n",
      "1   CUSTOM_GETCHROMSIZES                                         -   \n",
      "2      DEXSEQ_ANNOTATION  Drosophila_melanogaster.BDGP6.32.106.gtf   \n",
      "3  SALMON_GENOMEGENERATE                                         -   \n",
      "4    STAR_GENOMEGENERATE                                         -   \n",
      "\n",
      "                                                name     status  exit module  \\\n",
      "0  GFFREAD_TX2GENE (Drosophila_melanogaster.BDGP6...  COMPLETED     0      -   \n",
      "1                               CUSTOM_GETCHROMSIZES  COMPLETED     0      -   \n",
      "2  DEXSEQ_ANNOTATION (Drosophila_melanogaster.BDG...  COMPLETED     0      -   \n",
      "3                              SALMON_GENOMEGENERATE  COMPLETED     0      -   \n",
      "4                                STAR_GENOMEGENERATE  COMPLETED     0      -   \n",
      "\n",
      "   ... vol_ctxt  inv_ctxt env  \\\n",
      "0  ...       11        79   -   \n",
      "1  ...        2         4   -   \n",
      "2  ...       27       205   -   \n",
      "3  ...      426      1083   -   \n",
      "4  ...       19      1145   -   \n",
      "\n",
      "                                             workdir scratch  error_action  \\\n",
      "0  /workspace/rnaseq/work/90/a3cc1f2cdfc19b35a9cd...    True             -   \n",
      "1  /workspace/rnaseq/work/f2/938a2e977b8b24b5ee4a...    True             -   \n",
      "2  /workspace/rnaseq/work/44/547e6d76ad212a46f916...    True             -   \n",
      "3  /workspace/rnaseq/work/8c/886f8078e73853475a07...    True             -   \n",
      "4  /workspace/rnaseq/work/c3/1920aa54f83f03f90353...    True             -   \n",
      "\n",
      "  bandwidth node      mode replicate  \n",
      "0        No    4  baseline         1  \n",
      "1        No    4  baseline         1  \n",
      "2        No    4  baseline         1  \n",
      "3        No    4  baseline         1  \n",
      "4        No    4  baseline         1  \n",
      "\n",
      "[5 rows x 44 columns]\n",
      "Rows with NaN values:\n",
      "Empty DataFrame\n",
      "Columns: [hostname, task_id, hash, native_id, process, tag, name, status, exit, module, container, cpus, time, disk, memory, attempt, submit, start, complete, duration, realtime, queue, %cpu, %mem, rss, vmem, peak_rss, peak_vmem, rchar, wchar, syscr, syscw, read_bytes, write_bytes, vol_ctxt, inv_ctxt, env, workdir, scratch, error_action, bandwidth, node, mode, replicate]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 44 columns]\n",
      "\n",
      "Number of NaN values in each row:\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "bandwidths = ['No', '1Gbs'] \n",
    "nodes = [4, 8, 16] \n",
    "replicates_number = 2\n",
    "\n",
    "df_results = pd.DataFrame()\n",
    "prefix_path = \"/home/ninon/description_prototype_stuff/merging_results/\"\n",
    "reports_files = []\n",
    "\n",
    "for i in range(len(bandwidths)):\n",
    "    for j in range(len(nodes)):\n",
    "        for k in range(replicates_number):\n",
    "            mode = \"baseline\"\n",
    "            path = prefix_path +  str(bandwidths[i]) + \"/\"+ str(nodes[j]) + \"/\" + mode + \"/\" +  str(k+1)\n",
    "            prefix = \"_trace\"\n",
    "            #print(path)\n",
    "            if os.path.exists(path):\n",
    "                csv_files = [file for file in os.listdir(path) if file.startswith(prefix)]\n",
    "                for file in csv_files:\n",
    "                    file_path = os.path.join(path, file) \n",
    "                    df = pd.read_csv(file_path, delimiter=\"\\t\")\n",
    "                    df['bandwidth'] = str(bandwidths[i])\n",
    "                    df[\"node\"] = str(nodes[j]) \n",
    "                    df[\"mode\"] = mode \n",
    "                    df[\"replicate\"] =  str(k+1)\n",
    "                    df_results = df_results.append(df, ignore_index=True)\n",
    "            else:\n",
    "                mode = \"rewritten\"\n",
    "                path = prefix_path +  str(bandwidths[i]) + \"/\"+ str(nodes[j]) + \"/\" + mode + \"/\" +  str(k+1)\n",
    "                prefix = \"_trace\"\n",
    "                #print(path)\n",
    "                if os.path.exists(path):\n",
    "                    csv_files = [file for file in os.listdir(path) if file.startswith(prefix)]\n",
    "                    for file in csv_files:\n",
    "                        file_path = os.path.join(path, file) \n",
    "                        df = pd.read_csv(file_path, delimiter=\"\\t\")\n",
    "                        df['bandwidth'] = str(bandwidths[i])\n",
    "                        df[\"node\"] = str(nodes[j]) \n",
    "                        df[\"mode\"] = mode \n",
    "                        df[\"replicate\"] =  str(k+1)\n",
    "                        df_results = df_results.append(df, ignore_index=True)\n",
    "                else:\n",
    "                    #print(\"no\")\n",
    "                    continue\n",
    "\n",
    "print(df_results.head())\n",
    "\n",
    "# Find NaN values\n",
    "nan_rows = df[df.isna().any(axis=1)]\n",
    "nan_counts_per_row = nan_rows.isna().sum(axis=1)\n",
    "\n",
    "print(\"Rows with NaN values:\")\n",
    "print(nan_rows)\n",
    "print(\"\\nNumber of NaN values in each row:\")\n",
    "print(nan_counts_per_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute runtime for each experiment and compare baseline vs rewritten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7:16:03\n",
      "72.09622750695803\n",
      "7:20:49.500000\n",
      "73.09722529294716\n",
      "7:24:04.500000\n",
      "73.78908305408623\n",
      "7:21:00\n",
      "72.78428783627662\n",
      "7:18:12\n",
      "73.4598083317035\n",
      "7:19:21\n",
      "73.75975824729288\n",
      "  baseline runtime                 exp      rewritten runtime  \\\n",
      "0  0 days 10:04:49     No_band_4_nodes        0 days 02:48:46   \n",
      "1  0 days 10:03:04     No_band_8_nodes 0 days 02:42:14.500000   \n",
      "2  0 days 10:01:49    No_band_16_nodes 0 days 02:37:44.500000   \n",
      "3  0 days 10:05:54   1Gbs_band_4_nodes        0 days 02:44:54   \n",
      "4  0 days 09:56:31   1Gbs_band_8_nodes        0 days 02:38:19   \n",
      "5  0 days 09:55:39  1Gbs_band_16_nodes        0 days 02:36:18   \n",
      "\n",
      "            timediff_min  timediff_per  \n",
      "0        0 days 07:16:03     72.096228  \n",
      "1 0 days 07:20:49.500000     73.097225  \n",
      "2 0 days 07:24:04.500000     73.789083  \n",
      "3        0 days 07:21:00     72.784288  \n",
      "4        0 days 07:18:12     73.459808  \n",
      "5        0 days 07:19:21     73.759758  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def convert_to_timedelta(time_string):\n",
    "    components = {'h': 'hours', 'm': 'minutes', 's': 'seconds'}\n",
    "    time_parts = {components[part[-1]]: int(part[:-1]) for part in re.findall(r'\\d+[hms]', time_string)}\n",
    "    timedelta= datetime.timedelta(**time_parts)\n",
    "    return timedelta\n",
    "\n",
    "def convertStrToTimeFromReport(mstr):\n",
    "    runtime = mstr.split(\"</strong>\")[-2]\n",
    "    runtime = runtime.split(\"<strong>\")[1]\n",
    "    runtime = convert_to_timedelta(runtime)\n",
    "    return runtime\n",
    "\n",
    "def fetchRunTimeFromReport(file_path_list):\n",
    "    if( len(file_path_list) < 2 ):\n",
    "        with open(file_path_list[0], 'r') as file:\n",
    "            for line in file:\n",
    "                if ('completed_fromnow\"></span>duration: <strong>' in line):\n",
    "                    runtime = convertStrToTimeFromReport(line)\n",
    "                    break \n",
    "    else :\n",
    "        with open(file_path_list[0], 'r') as file:\n",
    "            for line in file:\n",
    "                if ('completed_fromnow\"></span>duration: <strong>' in line):\n",
    "                    runtime_1 = convertStrToTimeFromReport(line)\n",
    "                    break \n",
    "        with open(file_path_list[1], 'r') as file:\n",
    "            for line in file:\n",
    "                if ('completed_fromnow\"></span>duration: <strong>' in line):\n",
    "                    runtime_2 = convertStrToTimeFromReport(line)\n",
    "                    break \n",
    "        runtime = (runtime_1 + runtime_2) / 2\n",
    "    return runtime \n",
    "\n",
    "def computeDiffInRuntime(baseline, rewritten):\n",
    "    abs_diff = abs(baseline - rewritten)\n",
    "    percent_diff = (abs_diff / baseline) * 100\n",
    "    return abs_diff, percent_diff\n",
    "\n",
    "\n",
    "df_runtime = pd.DataFrame()\n",
    "\n",
    "prefix = \"_report\"\n",
    "\n",
    "for i in range(len(bandwidths)):\n",
    "    for j in range(len(nodes)):\n",
    "\n",
    "        #get baseline runtime values\n",
    "\n",
    "        mode = \"baseline\"\n",
    "        path = prefix_path +  str(bandwidths[i]) + \"/\"+ str(nodes[j]) + \"/\" + mode + \"/\" +  str(1)\n",
    "        path_replicate = prefix_path +  str(bandwidths[i]) + \"/\"+ str(nodes[j]) + \"/\" + mode + \"/\" +  str(1)\n",
    "        exp_name = str(bandwidths[i]) + \"_band_\" + str(nodes[j]) + \"_nodes\"\n",
    "\n",
    "        #check if replicate present\n",
    "        if (os.path.exists(path) and os.path.exists(path_replicate)):\n",
    "            # deal with average btw 2 runs\n",
    "            file = [file for file in os.listdir(path) if file.startswith(prefix)][0]\n",
    "            file_path = os.path.join(path, file) \n",
    "            file = [file for file in os.listdir(path_replicate) if file.startswith(prefix)][0]\n",
    "            file_path_replicate = os.path.join(path_replicate, file) \n",
    "            avg_runtime_baseline = fetchRunTimeFromReport([file_path, file_path_replicate])\n",
    "            baseline_runtime = avg_runtime_baseline\n",
    "        #else just one file is present\n",
    "        elif os.path.exists(path):\n",
    "            file = [file for file in os.listdir(path) if file.startswith(prefix)][0]\n",
    "            file_path = os.path.join(path, file) \n",
    "            runtime = fetchRunTimeFromReport([file_path])\n",
    "            baseline_runtime = runtime\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # get rewritten runtime values\n",
    "\n",
    "        mode = \"rewritten\"\n",
    "        path_rewritten = prefix_path +  str(bandwidths[i]) + \"/\"+ str(nodes[j]) + \"/\" + mode + \"/\" +  str(1)\n",
    "        path_replicate_rewritten = prefix_path +  str(bandwidths[i]) + \"/\"+ str(nodes[j]) + \"/\" + mode + \"/\" +  str(2)\n",
    "\n",
    "        # if replicate present\n",
    "        if (os.path.exists(path_rewritten) and os.path.exists(path_replicate_rewritten)):\n",
    "            file_rewritten = [file for file in os.listdir(path_rewritten) if file.startswith(prefix)][0]\n",
    "            file_path_rewritten = os.path.join(path_rewritten, file_rewritten) \n",
    "            file_rewritten = [file for file in os.listdir(path_replicate_rewritten) if file.startswith(prefix)][0]\n",
    "            file_path_replicate_rewritten = os.path.join(path_replicate_rewritten, file_rewritten) \n",
    "            avg_runtime_rewritten = fetchRunTimeFromReport([file_path_rewritten, file_path_replicate_rewritten])\n",
    "            rewritten_runtime = avg_runtime_rewritten\n",
    "        \n",
    "        #else\n",
    "        elif os.path.exists(path_rewritten):\n",
    "            file_rewritten = [file for file in os.listdir(path_rewritten) if file.startswith(prefix)][0]\n",
    "            file_path_rewritten = os.path.join(path_rewritten, file_rewritten)\n",
    "            runtime = fetchRunTimeFromReport([file_path_rewritten])\n",
    "            rewritten_runtime = runtime\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        timediff_min, timediff_per = computeDiffInRuntime(baseline_runtime, rewritten_runtime)\n",
    "        new_row = {'exp': exp_name, 'baseline runtime': baseline_runtime, 'rewritten runtime': rewritten_runtime, 'timediff_min': timediff_min, 'timediff_per':timediff_per}\n",
    "        df_runtime = df_runtime.append(new_row, ignore_index=True)\n",
    "\n",
    "print(df_runtime)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
